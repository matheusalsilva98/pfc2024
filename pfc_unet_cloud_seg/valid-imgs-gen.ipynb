{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataset import CBERS4A_CloudDataset\n",
    "from model import UNet\n",
    "import config\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = '/media/reginaldo/pfc-dados/dataset-piloto/dados-validacao/images_LOCAL_CONFIG_6bands'\n",
    "masks_dir = '/media/reginaldo/pfc-dados/dataset-piloto/dados-validacao/masks_LOCAL_CONFIG'\n",
    "\n",
    "val_ds = CBERS4A_CloudDataset(imgs_dir=imgs_dir, masks_dir=masks_dir)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "                            val_ds,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            num_workers=config.BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualization(fig_title=None, fig_size=None, font_size=16, **images):\n",
    "        n = len(images)\n",
    "        fig_size = (16, 5) if fig_size is None else fig_size\n",
    "        fig, axarr = plt.subplots(1, n, figsize=fig_size)\n",
    "        if fig_title is not None:\n",
    "            fig.suptitle(fig_title, fontsize=font_size)\n",
    "        for i, (name, image) in enumerate(images.items()):\n",
    "            plt.subplot(1, n, i + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(\" \".join(name.split(\"_\")).title())\n",
    "            if image.shape == (4, 512, 512):\n",
    "                image.transpose([1,2,0])\n",
    "                image = image[:,:,:3]\n",
    "            plt.imshow(image)\n",
    "        fig.subplots_adjust(top=0.8)\n",
    "        return axarr, fig\n",
    "\n",
    "def save_inference_to_disk(plot, image_name, output_path):\n",
    "    image_name = Path(image_name).name.split(\".\")[0]\n",
    "    report_path = os.path.join(\n",
    "        output_path,\n",
    "        \"report_image_{name}.jpg\".format(\n",
    "            name=image_name,\n",
    "        ),\n",
    "    )\n",
    "    plot.savefig(report_path, format=\"jpg\", bbox_inches=\"tight\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['/media/reginaldo/pfc-dados/dataset-piloto/testes/treino1/epoch=25-step=1846.ckpt',\n",
    "          '/media/reginaldo/pfc-dados/dataset-piloto/testes/treino2/epoch=60-step=4331.ckpt',\n",
    "          '/media/reginaldo/pfc-dados/dataset-piloto/testes/treino3/epoch=44-step=3870.ckpt',\n",
    "          '/media/reginaldo/pfc-dados/dataset-piloto/testes/treino4/epoch=53-step=4644.ckpt',\n",
    "          '/media/reginaldo/pfc-dados/dataset-piloto/testes/treino5/epoch=67-step=5848.ckpt']\n",
    "model_1, model_2, model_3, model_4, model_5 = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_inference(dataloader=val_dataloader):\n",
    "\n",
    "    val_dl = dataloader.dataset\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = UNet.load_from_checkpoint(checkpoint_path=model_5)\n",
    "    model = model.float()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_dl):\n",
    "            if idx % 1000 == 0:\n",
    "                images, masks = batch['image'], batch['mask']\n",
    "\n",
    "                images = images.unsqueeze(0)\n",
    "                images = images.to(device)\n",
    "\n",
    "                # mask plot preparation\n",
    "                predicted_mask = model(images)\n",
    "                predicted_mask = predicted_mask.to(\"cpu\")\n",
    "\n",
    "                masks = masks.numpy().astype(np.uint8)\n",
    "                masks = np.squeeze(masks)\n",
    "\n",
    "                # image plot preparation\n",
    "                images = images.to(\"cpu\")\n",
    "                images = images.numpy()\n",
    "                images = np.squeeze(images)\n",
    "                images = (images / images.max()) * 255.\n",
    "                images = images.astype(np.uint8)\n",
    "                images = images.transpose((1,2,0))\n",
    "                images = images[:,:,:3]\n",
    "\n",
    "                # predicted mask plot preparation\n",
    "                predicted_mask = predicted_mask.numpy()\n",
    "                predicted_mask = np.squeeze(predicted_mask)\n",
    "                predicted_mask = np.argmax(predicted_mask, axis=0)\n",
    "                predicted_mask = predicted_mask.astype(np.uint8)\n",
    "                \n",
    "                plot_title = f'batch_{idx}'\n",
    "                plt_result, fig = generate_visualization(\n",
    "                    image=images,\n",
    "                    ground_truth_mask=masks,\n",
    "                    predicted_mask=predicted_mask)\n",
    "\n",
    "                save_inference_to_disk(fig, plot_title, output_path='/media/reginaldo/pfc-dados/dataset-piloto/dados-validacao/resultados-treino5')\n",
    "\n",
    "            plt.close(fig)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.7.1 to v2.3.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../media/reginaldo/pfc-dados/dataset-piloto/testes/treino5/epoch=67-step=5848.ckpt`\n"
     ]
    }
   ],
   "source": [
    "val_inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
